---
title: "Project 01"
subtitle: "Ensemble Q-Q and GLM"
jupyter: julia-1.9
date: 2023-11-10
author: "Aaron Xu (ax16)" 

number-sections: true
code-annotations: hover

kind: "Project"
Module: "3"
categories:
    - "Module 2"
    - "Labs"

format:
    html: 
        toc-depth: 3
    docx: 
        toc: true
        toc-depth: 3
        fig-format: png
---
```{julia}
#| output: false
using Dates
using MultivariateStats
using Plots
using NCDatasets
using StatsBase
using Unitful
using DataFrames
using Distributions
using StatsPlots
using Turing
using DynamicHMC
```
# Exectuive Summary 

In this project, my objective was to model hourly precipitation at a single location given the total precipitation of that day. There are many ways to approach this problem. I opted to explore the capability of generalized linear models. Initially, I created a GLM that related the hourly temperature to the hourly precipitation. Then I created a GLM that related the hourly temperature and the hourly change in temperature to the hourly precipitation. The precipitation could then be estimated provided there is data on temperature. If there are concerns about the correlational support between temperature and precipitation, they are valid, because model performance was laughably bad. Quantile-Quanitle plots between training data and model output showed no clear trends. However, if daily total precipitation were used as a limit for model output, Q-Q correlation may improve by about a factor of 10. 

## GLM Specifics 

I assumed that the distribution of hourly precipitation for annual observation period could be described by a log-normal curve. Given this assumption, the intensity of hourly precipitation can be described using two paramters, $\mu$ the mean and $\sigma$ is the standard deviation. I estimated these parameters using these equations.

$$\mu_i = \alpha+\beta x_i $$ 
{#eq-a}

$$\sigma_i = | \gamma+\chi x_i |$$
{#eq-b}


Note that I have chosen to use the identity link function for equation @eq-a and a non-cononical absolute value for @eq-b. The idenity link function was chosen as $\mu \in (-\infty,\infty)$ and, the absolute value function was chosen as $\sigma \in (0,\infty)$. 

## Using Observed Daily Total Precipitation as a Boundary Condition 

If I sampled from a distribution for $y_i(x_i |\theta)$ twentyfour times, the sum would not be guarranteed to stay within the observed daily precipitation for that time period. To prevent overestimating daily precipitation, I reject any sample of the distribution of $y_i(x_i|\theta)$ that put the total daily precipitation above the corresponding observation. 


# Data Import 
```{julia}
#| echo: false
#| output: false
# file list
    t2m_obj = NCDataset("data/raw/2m_temperature_2019.nc") #kelvin
    t2m_time = Dates.Date.(t2m_obj["time"][:])
    t2m_lon =  t2m_obj["longitude"][:]
    t2m_lat = t2m_obj["latitude"][:]
    t2m_vals = t2m_obj["t2m"][:,:,:].*u"K"
    close(t2m_obj)

    tp_obj = NCDataset("data/raw/Total_precipitation_2019.nc") #meters -> mm
    tp_time = Dates.Date.(tp_obj["time"][:])
    tp_lon =  tp_obj["longitude"][:]
    tp_lat = tp_obj["latitude"][:]
    tp_vals = tp_obj["tp"][:,:,:].* u"m" .* 1000u"mm"./u"m"
    close(tp_obj)

    cpc_obj = NCDataset("data/raw/precip_tx.nc") #mm
    cpc_time = Dates.Date.(cpc_obj["time"][:])
    cpc_lon = 180 .- cpc_obj["lon"][:]
    cpc_lat = cpc_obj["lat"][:]
    cpc_vals = cpc_obj["precip"][:,:,:].*u"mm"
    close(cpc_obj)
```
If you can see the following heatmaps, that means the data was succesfully imported. Since I am only downscaling temporally, I do not need the entire grid. I have choosen to use the time series at -84 degrees east and 33 degrees north.

```{julia}
a = heatmap(t2m_vals[:,:,:1])
b = heatmap(tp_vals[:,:,1])
c = heatmap(cpc_vals[:,:,1])
plot(a,b,c)
```

```{julia}
#| echo: false
#| output: false
println(t2m_lon) # I choose -84.0
println(tp_lon) 
println(cpc_lon) # I choose -84.25
```
```{julia}
#| echo: false
#| output: false
println(t2m_lat) # I choose 33.0 
println(cpc_lat) # I choose 32.75
```

```{julia}
#| echo: false
#| output: false
# Find indecies
era_lon = argmin(abs.(t2m_lon .+ 84.0))
era_lat = argmin(abs.(t2m_lat .- 33.0))
cpc_lon = argmin(abs.(cpc_lon .+ 84.25))
cpc_lat = argmin(abs.(cpc_lat .- 32.75))

# Temporarily Setting Time Domain
year_start = Dates.Date(2019,1,1)
year_end = Dates.Date(2019,12,31)

# Extracting Time Series from Location
t2m_loc = t2m_vals[era_lon,era_lat,:]
tp_loc = tp_vals[era_lon,era_lat,:]
cpc_loc = cpc_vals[cpc_lon,cpc_lat, (cpc_time .<= year_end) .* (cpc_time .>= year_start)];
cpc_time = cpc_time[(cpc_time .<= year_end) .* (cpc_time .>= year_start)]
println("t2m_loc size: ",size(t2m_loc))
println("tp_loc size: ",size(tp_loc))
println("cpc_loc size: ",size(cpc_loc))
```
# Data Wrangling and Exploration 
```{julia}
#| echo: false
#| output: false

# Creating DataFrames for my data
df_era_hr = DataFrame(time = t2m_time, temp = t2m_loc, precip = tp_loc)
filter = vec(df_era_hr[!,:precip].< (0.0u"mm"))
df_era_hr[filter,:precip] .= 0.0*u"mm"
df_era_d = combine(groupby(df_era_hr,:time),:precip => sum)
df_cpc_d = DataFrame(time = cpc_time, precip = cpc_loc)
df_d = innerjoin(df_era_d, df_cpc_d, on = :time, renamecols = "_era" => "_cpc")
```
## Distribution of Hourly Temperature and Precipitation (all ERA5)

```{julia}
#| echo: false
#| label: fig-ERA5-all
#| fig-cap: "Distributions of hourly temperature and precipitation from the ERA5 dataset. a) The distribution of hourly precipitation. The distribution is dominated by zeros. b) The distribution of hourly temperature 2 meters above ground. The data appears slightly left skewed. c) Hourly precipitation against hourly temperature. There is a very weak negative correlation (corr = -0.017) "
# Plot Distribution of Hourly Temperature and RainFall (all ERA5)
a = histogram(df_era_hr[!,:precip],normalize = :pdf, title ="a)")
b = histogram(df_era_hr[!,:temp], normalize = :pdf,title = "b)")
c = scatter(df_era_hr[!,:temp],df_era_hr[!,:precip], title = "c)") # slight positive trend 
#display(cor(df_era_hr.temp./u"K",df_era_hr.precip./u"mm"))
plot(a,b,c)
```

```{julia}
#| echo: false
#| fig-cap: "Distributions of hourly temperature and precipitation from the ERA5 with only nonzero precipitation obervations. a) The distribution of hourly precipitation. b) The distribution of hourly temperature 2 meters above ground. c) Hourly precipitation against hourly temperature. There is a  weak negative correlation (corr = -0.10) "
# Plot Distribution of Hourly Temperature and RainFall (all ERA5)
# Plot Distribution of Hourly Temperature and RainFall (all ERA5)
filter = df_era_hr[!,:precip] .> 0.0u"mm" 
a = histogram(df_era_hr[filter,:precip],normalize = :pdf)
b = histogram(df_era_hr[filter,:temp],normalize = :pdf)
c = scatter(df_era_hr[filter,:temp],df_era_hr[filter,:precip]) # no change in shapes when low values are cut. I don't think theres a strong correlation. 
#display(cor(df_era_hr.temp[filter]./u"K",df_era_hr.precip[filter]./u"mm"))
plot(a,b,c)
```

```{julia}
#| echo: false 
#| fig-cap: "Distribution of daily total precipitation from the ERA5 model and CPC obvervations. The correlation of data shown in c) is (cor = 0.025)."
# Plot Distribution of Daily Precipitation from ERA5 and CPC obvervations
a = histogram(df_d[!,:precip_sum_era],title = "a) ERA5")
b = histogram(df_d[!,:precip_cpc], title = "b) CPC")
c= scatter(df_d[!,:precip_cpc],df_d[!,:precip_sum_era],title = "c) Q-Q", xlabel = "CPC",ylabel = "ERA5") # absolute garbage 
#display(cor(df_d[!,:precip_sum_era]./u"mm",df_d[!,:precip_cpc]./u"mm"))
plot(a,b,c)
```
## Exploring Distribution Fitting 
```{julia}
#| echo: false
function plot_dist(dist; name="", xlims=missing)
    ub = quantile(dist, 0.998)
    lb = quantile(dist, 0.002)
    p = plot(x -> pdf(dist, x); ylabel="Probability Density", label=name, xlims=(lb, ub))
    !ismissing(xlims) && xlims!(p, xlims)
    return p
end
```
The distribution of rainfall is not gaussian in any way. We've discussed in class that there are a series of distributions we should try fitting. First try a log-normal distribution, then a log pearson III distribution, and a extreme value distribution for last resort. I first fitted the data to a log-normal distribution and it looked pretty good (@lognormal). Unfortunatley, I couldn't fit a Pareto or a Weibull distribution without getting errors or bogus distributions, so I will stick with a log-normal distribution.

```{julia}
#| echo: false
#| label: lognormal
#| fig-cap: By eye, A log-normal fit describes hourly precipitation fairly well. The parameters for the log-normal distribution are μ=-3.04 and σ=2.39. 
fitted = fit(LogNormal,(df_era_hr[df_era_hr.precip .> 0.0u"mm",:precip]./u"mm")) 

histogram(df_era_hr[df_era_hr.precip .> 0.0u"mm",:precip]./u"mm",normalize = true,xlims=(0,3),xlabel = "Hourly Precipitation (mm) ", ylabel = "p")

plot!(fitted,xlims=(0,3),linewidth = 3)

```
I also checked the distribution of precipitation given certain ranges of temperature. I wanted to see if the distribution parameters changed at all, and they did change throught the temperature brackets (@lognormal-cuts .b). 

```{julia}
#| echo: false
#| label: lognormal-cuts
#| fig-cap: 
#| #| fig-subcap: The log-normal distribution also does well with different cuts of precipitation, by temperature. 
#|   - "Histograms and fitted distributions."
#|   - "Parameters for each fit."

####
filter = (df_era_hr.precip .> 0.0u"mm") .* (df_era_hr.temp .< 283.0u"K")

fitted_A = fit(LogNormal,(df_era_hr[filter,:precip]./u"mm")) 

a = histogram(  df_era_hr[filter,:precip]./u"mm",
                normalize = true,
                xlims=(0,3), 
                ylabel = "p",
                title = "i) T < 283.0 K")

plot!(fitted_A,xlims=(0,3),linewidth = 3)

####
filter = (df_era_hr.precip .> 0.0u"mm") .* (df_era_hr.temp .< 293.0u"K") .*(df_era_hr.temp .> 283.0u"K")

fitted_B = fit(LogNormal,(df_era_hr[filter,:precip]./u"mm")) 

b = histogram(  df_era_hr[filter,:precip]./u"mm",
                normalize = true,
                xlims=(0,3),
                title = "ii) 283 < T < 293 K")

plot!(fitted_B,xlims=(0,3),linewidth = 3)

####
filter = (df_era_hr.precip .> 0.0u"mm") .* (df_era_hr.temp .< 303.0u"K").*(df_era_hr.temp .> 293.0u"K")

fitted_C = fit(LogNormal,(df_era_hr[filter,:precip]./u"mm")) 

c = histogram(  df_era_hr[filter,:precip]./u"mm",
                normalize = true,
                xlims=(0,3),
                xlabel = "Hourly Precipitation (mm) " ,
                ylabel = "p", 
                title = "iii) 293 K < T < 303 K")
    
plot!(fitted_C,xlims=(0,3),linewidth = 3)

####
filter = (df_era_hr.precip .> 0.0u"mm") .* (df_era_hr.temp .< 313.0u"K").*(df_era_hr.temp .> 303.0u"K")

fitted_D = fit(LogNormal,(df_era_hr[filter,:precip]./u"mm")) 

d= histogram(   df_era_hr[filter,:precip]./u"mm",
                normalize = true,
                xlims=(0,3),
                xlabel = "Hourly Precipitation (mm)",
                title = "iv) 303 K < T < 313 K")

plot!(fitted_D,xlims=(0,3),linewidth = 3)

println("i)   ",fitted_A,'\n',
        "ii)  ",fitted_B,'\n',
        "iii) ", fitted_C,'\n',
        "iv)  ", fitted_D)


###########
plot(a,b,c,d)
```

# Methods 
1. Create a GLM using temperature to predict precipitation 
2. Write a function that predicts precipitation given GLM parameters, temperature, precipitation already predicted for the day, and the observed daily precipitation.

## Create a GLM using temperature to predict precipitation  
```{julia}
function link_function1(value)
    return value
end

function link_function2(value)
    return abs(value)
end

@model function regression_glm(y::AbstractVector, x::AbstractVector)
        α ~ Normal(0, 1)
        β ~ Normal(0, 1)
        γ ~ Normal(0, 1)
        χ ~ Normal(0, 1)
        for i in eachindex(y)
            μ = link_function1(α + β * x[i])
            σ = link_function2(γ + χ * x[i])
            y[i] ~ LogNormal(μ,σ)
        end
end

@model function regression_lr(y::AbstractVector, x::AbstractVector)
        α ~ Normal(0, 1)
        β ~ Normal(0, 1)
        σ ~ Normal(0,1)
        for i in eachindex(y)
            μ = α + β * x[i]
            y[i] ~ LogNormal(μ,σ)
        end
end
```

```{julia}
X = df_era_hr.temp[df_era_hr.precip .> 0.0u"mm"]./u"K"
y = df_era_hr.precip[df_era_hr.precip .> 0.0u"mm"]./u"mm"
```

```{julia}
glm_chn = let
    model = regression_glm( y , X )
    sampler = externalsampler(DynamicHMC.NUTS())
    nsamples = 100
    sample(model, sampler, nsamples; drop_warmup=true)
end
a = plot(glm_chn)
```

```{julia}
lr_chn = let
    model = regression_lr( y , X )
    sampler = externalsampler(DynamicHMC.NUTS())
    nsamples = 100
    sample(model, sampler, nsamples; drop_warmup=true)
end
b = plot(lr_chn)
```

```{julia}
function predict_precip_one_glm(chn,T_i, R_n, RD)
    elapsed_precip = sum(R_n) 
    max_precip = RD 

    α = mean(chn[:α])
    β = mean(chn[:β])
    γ = mean(chn[:γ])
    χ = mean(chn[:χ])

    μ = link_function1(α+β*T_i)
    #print(size(μ))
    σ = link_function2(γ+χ*T_i)
    #print(size(σ))
    dist = LogNormal(μ,σ)
    R_i = [Inf64]
    LL_i = 0.0
    #print(typeof(R_i))
    #print(typeof(max_precip))
    #print(typeof(elapsed_precip))
    counter = 0
    #println("maxL", max_precip)
    if max_precip == 0.0
        R_i[1] = 0.0
        #println("nob")
    else
        #println("coooob")
        while ((R_i[1] > (max_precip-elapsed_precip))  | (R_i == Inf))
            counter = counter + 1 
            if (max_precip - elapsed_precip) < 0.0 
                R_i[1] = 0.0 
                LL_i = 0.0
                break
            end
            R_i[1] = rand(dist,1)[1]
            LL_i = logpdf(dist,R_i[1])

            if (R_i[1]+elapsed_precip) > max_precip
                R_i[1] = Inf 
                LL_i = -Inf
            end

            if counter > 100
                R_i[1]= 0.0
                LL_i = 0.0 
                break
            end
            
        end

    end

    return R_i[1],LL_i
end
```

Output of this section should be parameters to obtain the distribution of hourly rainfall given an hourly 2meter-temperature. 

```{julia}
function predict_precip_one_lr(chn,T_i, R_n, RD)
    elapsed_precip = sum(R_n) 
    max_precip = RD 

    α = mean(chn[:α])
    β = mean(chn[:β])
    σ = mean(chn[:σ])
    μ = α+β*T_i
    #print(size(μ))
    
    #print(size(σ))
    dist = LogNormal(μ,σ)
    R_i = [Inf64]
    LL_i = 0.0
    #print(typeof(R_i))
    #print(typeof(max_precip))
    #print(typeof(elapsed_precip))
    counter = 0
    #println("maxL", max_precip)
    if max_precip == 0.0
        R_i[1] = 0.0
        #println("nob")
    else
        #println("coooob")
        while ((R_i[1] > (max_precip-elapsed_precip))  | (R_i == Inf))
            counter = counter + 1 
            if (max_precip - elapsed_precip) < 0.0 
                R_i[1] = 0.0 
                LL_i = 0.0
                break
            end
            R_i[1] = rand(dist,1)[1]
            LL_i = logpdf(dist,R_i[1])

            if (R_i[1]+elapsed_precip) > max_precip
                R_i[1] = Inf 
                LL_i = -Inf
            end

            if counter > 100
                R_i[1]= 0.0
                LL_i = 0.0 
                break
            end
            
        end

    end

    return R_i[1],LL_i
end
```

## Testing 
```{julia}
function run_model(df_era_hr_passer,df_d,logistic_chn,predict_func)
df_era_hr = df_era_hr_passer
df_era_hr[!,:model] = df_era_hr.precip.*0.0
df_era_hr[!,:loglikelihood] = df_era_hr.precip ./u"mm" .*0.0
for (a_idx,a) in enumerate(eachrow(df_d[:,:]))
    offset_start = (a_idx-1)*24+1 
    offset_end = (a_idx)*24

    for (idx,b) in enumerate(eachrow(df_era_hr[offset_start:offset_end ,:]))
        if idx != 1
            R_n = df_era_hr[offset_start:offset_end,:model]./u"mm"
        else
            R_n = [0.0]
        end
        R_i,LL_i = predict_func(logistic_chn,
                                b[:temp]./u"K",
                                R_n,
                                a[:precip_sum_era]./u"mm")

        #println("R_i  ", R_i )
        #println("Idx ", idx)
        #println("max_precip",a[:precip_sum_era])
        df_era_hr[(idx-1)+offset_start,:model] = R_i * u"mm"
        df_era_hr[(idx-1)+offset_start,:loglikelihood] = LL_i[1]
    end
end

    
    return  df_era_hr 
end
```
```{julia}
function analytics(df_era_hr)
    total_precip = sum(df_era_hr.precip[:])
    total_modeled_precip = sum(df_era_hr.model[:])
    model_likelihood = sum(df_era_hr.loglikelihood)
    model_training_correlation = cor(df_era_hr.precip./u"mm",df_era_hr.model./u"mm")

    mse = sum((df_era_hr.precip[:] .- df_era_hr.model[:]).^2)

    model_v_obs_line = plot(df_era_hr.precip[:])
    plot!(df_era_hr.model[:])
    model_v_obs_scatter = scatter(df_era_hr.precip, df_era_hr.model)
    
    return (DataFrame(  total_precip = total_precip ,
                        total_modeled_precip = total_modeled_precip,model_likelihood = model_likelihood,
                        model_obs_correlation = model_training_correlation,
                        mse = mse), model_v_obs_line, model_v_obs_scatter)
end
```

```{julia}
lr_result = run_model(df_era_hr,df_d,lr_chn,predict_precip_one_lr)
lr_stats, lr_line, lr_scatter = analytics(lr_result)

for i in 1:100
    temp_lr_result = run_model(df_era_hr,df_d,lr_chn,predict_precip_one_lr)
    temp_lr_stats, temp_lr_line, temp_lr_scatter = analytics(lr_result)
    append!(lr_stats,temp_lr_stats)
end
```

```{julia}
glm_result = run_model(df_era_hr,df_d,glm_chn,predict_precip_one_glm)
glm_stats, glm_line, glm_scatter = analytics(glm_result)

for i in 1:100
    temp_glm_result = run_model(df_era_hr,df_d,glm_chn,predict_precip_one_glm)
    temp_glm_stats, temp_glm_line, temp_glm_scatter = analytics(glm_result)
    append!(glm_stats,temp_glm_stats)
end
```

```{julia}
reconstruct_daily_precip = combine(groupby(df_era_hr,:time), :precip  => sum, :model => sum, :loglikelihood => sum)

a = plot(reconstruct_daily_precip.precip_sum)
plot!(reconstruct_daily_precip.model_sum)
b = scatter(reconstruct_daily_precip.precip_sum,reconstruct_daily_precip.model_sum)
plot(a,b)
```
# Model Comparison

# Conclusion
